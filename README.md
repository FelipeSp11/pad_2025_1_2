# Proyecto PAD: Automatizaci√≥n de Extracci√≥n e Ingesta de Datos con DevOps

## üìù Autores

* **Le√≥n Felipe S√°nchez Palacio**

## üìö Descripci√≥n del Proyecto

Este proyecto forma parte de la asignatura de Programaci√≥n para An√°lisis de Datos (PAD) y tiene como objetivo principal demostrar un flujo de trabajo DevOps completo y automatizado para la extracci√≥n y gesti√≥n de datos. La aplicaci√≥n desarrollada extrae informaci√≥n de una p√°gina web espec√≠fica (referente a precios hist√≥ricos del oro), procesa los datos y los persiste en una base de datos local. Todo el proceso est√° encapsulado en contenedores Docker y orquestado mediante un pipeline de Integraci√≥n Continua y Despliegue Continuo (CI/CD) implementado con GitHub Actions.

Se hace √©nfasis en las siguientes pr√°cticas:
* **Control de Versiones:** Gesti√≥n robusta del c√≥digo fuente utilizando Git y GitHub.
* **Contenerizaci√≥n:** Empaquetado de la aplicaci√≥n en im√°genes Docker para asegurar la portabilidad y la consistencia del entorno.
* **CI/CD:** Automatizaci√≥n de la construcci√≥n, prueba y despliegue de la aplicaci√≥n a trav√©s de GitHub Actions.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Lenguaje de Programaci√≥n:** Python 3.9+
* **Librer√≠as Python:**
    * `BeautifulSoup4`: Para el web scraping.
    * `pandas`: Para la manipulaci√≥n y an√°lisis de datos.
    * Otras librer√≠as
* **Contenerizaci√≥n:** Docker
* **Control de Versiones:** Git
* **Plataforma de Repositorio:** GitHub
* **CI/CD:** GitHub Actions


## üìÅ Estructura del Repositorio

El repositorio est√° organizado de la siguiente manera:
‚îú‚îÄ‚îÄ .github/                 # Configuraciones de GitHub
‚îÇ   ‚îî‚îÄ‚îÄ workflows/           # Workflows de GitHub Actions para CI/CD
‚îÇ       ‚îî‚îÄ‚îÄ accionables.yml  # Definici√≥n del pipeline CI/CD
‚îú‚îÄ‚îÄ src/                     # C√≥digo fuente de la aplicaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ edu_pad/             # Paquete principal de la aplicaci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ init.py
‚îÇ       ‚îú‚îÄ‚îÄ database.py      # M√≥dulo para la interacci√≥n con la base de datos
‚îÇ       ‚îú‚îÄ‚îÄ main_extractor.py # Script principal para la extracci√≥n y procesamiento de datos
‚îÇ       ‚îú‚îÄ‚îÄ main_ingesta.py   # Script principal para la ingesta de datos
‚îÇ       ‚îî‚îÄ‚îÄ static/          # Archivos est√°ticos, como CSVs y DBs
‚îÇ           ‚îú‚îÄ‚îÄ csv/         # Directorio para archivos CSV (input/output)
‚îÇ           ‚îî‚îÄ‚îÄ db/          # Directorio para archivos de base de datos
‚îú‚îÄ‚îÄ Dockerfile               # Definici√≥n de la imagen Docker de la aplicaci√≥n
‚îú‚îÄ‚îÄ requirements.txt         # Dependencias de Python
‚îî‚îÄ‚îÄ README.md                # Este archivo

## üöÄ Flujo de Trabajo DevOps Implementado

El coraz√≥n de este proyecto es su pipeline de CI/CD, que automatiza el ciclo de vida del software desde el desarrollo hasta el despliegue.

### 1. Control de Versiones (Git & GitHub)

* Utilizamos un flujo de trabajo de Git basado en ramas, donde `main` es la rama principal que representa la versi√≥n estable y desplegable del c√≥digo.
* Cada nueva funcionalidad o correcci√≥n se desarrolla en una rama separada.
* Los `pull requests` se utilizan para revisar y fusionar el c√≥digo en la rama `main`, garantizando la calidad y la colaboraci√≥n.

### 2. Contenerizaci√≥n (Docker)

* **Dockerfile:** El `Dockerfile` en la ra√≠z del repositorio define c√≥mo construir la imagen Docker de la aplicaci√≥n. Esta imagen incluye Python, todas las dependencias necesarias y el c√≥digo fuente del proyecto. Esto asegura que el entorno de ejecuci√≥n de la aplicaci√≥n sea id√©ntico en desarrollo y en el pipeline de CI/CD.
* **Imagen `contenedor`:** Se construye una imagen Docker con el nombre `contenedor`  que encapsula toda la l√≥gica de extracci√≥n e ingesta de datos.

### 3. Pipeline de CI/CD (GitHub Actions)

El archivo `.github/workflows/docker.yml` define el pipeline de CI/CD que se activa autom√°ticamente con cada `push` a la rama `main`.

**Pasos del Workflow:**

1.  **`name: Paso 5 - Ejecutar ingesta`**: (Ajusta el nombre del paso principal si tu workflow tiene m√°s funcionalidades o est√° enfocado en `extractor` o `ingesta`).
2.  **`on: push: branches: [main]`**: El workflow se dispara autom√°ticamente cada vez que se realiza un `push` a la rama `main`.
3.  **`jobs: build: runs-on: ubuntu-latest`**: El pipeline se ejecuta en un ambiente Linux (ubuntu-latest).
4.  **`steps:`**:
    * **`Checkout repo`**: Clona el repositorio en el runner de GitHub Actions.
    * **Configuraci√≥n del Entorno Docker:**
        * (Opcional, si tu Dockerfile es complejo o si necesitas construir la imagen en el workflow): Se podr√≠a a√±adir un paso `docker build -t contenedor .` aqu√≠ para construir la imagen antes de ejecutarla.
    * **Ejecuci√≥n de M√≥dulos Python en Docker:**
        * Los scripts `main_extractor.py` y `main_ingesta.py` se ejecutan dentro del contenedor Docker. Esto asegura que la aplicaci√≥n se ejecute en un ambiente aislado y reproducible, con todas las dependencias preinstaladas en la imagen.
        * **Mapeo de Vol√∫menes:** Se utilizan vol√∫menes (`-v`) para persistir datos y permitir la comunicaci√≥n entre el host (el runner de GitHub Actions) y el contenedor.
            * `-v "${{ github.workspace }}/static/csv":/src/edu_pad/static/csv`: Mapea la carpeta `static/csv` del repositorio a `/src/edu_pad/static/csv` dentro del contenedor. Esto permite que el script `main_ingesta.py` lea el `data_webdb.csv` (generado previamente por `main_extractor.py` o existente en el repo) y que `main_extractor.py` guarde su salida.
            * `-v "${{ github.workspace }}/static/db":/src/edu_pad/static/db`: Mapea la carpeta `static/db` del repositorio a `/src/edu_pad/static/db` dentro del contenedor, asegurando que la base de datos sea accesible y que los cambios se persistan.
        * **Comando de Ejecuci√≥n:** `contenedor python -m edu_pad.main_ingesta` (o `edu_pad.main_extractor` para el otro paso). Este comando le dice a Docker que use la imagen `contenedor` y ejecute el m√≥dulo Python especificado.

5.  **Despliegue Continuo (Sincronizaci√≥n de Artefactos):**
    * `stefanzweifel/git-auto-commit-action@v4`: Esta acci√≥n autom√°ticamente hace un commit y push de los cambios. Esto simula un despliegue continuo de los datos procesados en el propio repositorio.

## üöÄ C√≥mo Ejecutar el Proyecto (Localmente)

Para ejecutar este proyecto localmente fuera del pipeline de CI/CD:

### Prerequisitos

* Docker Desktop (o Docker Engine) instalado y en ejecuci√≥n.
* Python 3.9+ instalado.
* Git instalado.

### Pasos

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/FelipeSp11/pad_2025_1_2.git](https://github.com/FelipeSp11/pad_2025_1_2.git)
    cd pad_2025_1_2
    ```

2.  **Construir la imagen Docker:**
    ```bash
    docker build -t contenedor .
    ```
    Esto crear√° una imagen Docker llamada `contenedor` a partir de tu `Dockerfile`.

3.  **Ejecutar el proceso de Extracci√≥n (Extractor):**
    Aseg√∫rate de que la carpeta `static/csv` exista en tu directorio local.
    ```bash
    mkdir -p static/csv static/db
    docker run --rm \
    -v "$(pwd)/static/csv":/src/edu_pad/static/csv \
    -v "$(pwd)/static/db":/src/edu_pad/static/db \
    contenedor python -m edu_pad.main_extractor
    ```
    Este comando ejecutar√° el `main_extractor.py` dentro del contenedor. El archivo `data_webdb.csv` (y otros que `extractor` genere) se guardar√° en tu carpeta `static/csv` local.

4.  **Ejecutar el proceso de Ingesta (Ingesta):**
    Aseg√∫rate de que el `data_webdb.csv` exista en `static/csv` y que la carpeta `static/db` est√© lista.
    ```bash
    docker run --rm \
    -v "$(pwd)/static/csv":/src/edu_pad/static/csv \
    -v "$(pwd)/static/db":/src/edu_pad/static/db \
    contenedor python -m edu_pad.main_ingesta
    ```
    Este comando ejecutar√° el `main_ingesta.py`, leyendo el CSV y procesando los datos en la base de datos.


  
## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles. (Crea un archivo LICENSE si no lo tienes).

---